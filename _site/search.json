[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Biologist, data scientist, and hobbyist coder\n\nmail • github • blog\n\n\n\nNCSOFT 엔씨 (South Korea), Lead of Data Center\n\n\nData analytics, Economics\n\n\n\n\nEconometric analysis on online gaming behaviors\nReal-money trading in online games\nGame theory\n\n\n\n\n\n2019.02 -- present NCSOFT, Data Center (Seongnam Gyeonggi · South Korea) - Lead (executive director) - managing the group of data scientists\n2018.03 -- 2019.01 NCSOFT, I&I Division - Lead\n2014.08 -- 2018.03 NCSOFT, R&I Team - Lead\n2013.05 -- 2014.07 KISDI\\(^*\\) (Jinchun Chungchungbuk · South Korea) - \\(*\\) Korea Information Society Development Institute 정보통신정책연구원 - Senior Researcher (Telecommunication Unit)\n2012.01 -- 2013.03 FourThirtyThree 네시삼십삼분 (Seoul · South Korea) - Data Analyst, Consultant\n2011.03 -- 2012.02 Seoul National University 서울대학교 (Seoul · South Korea) - Postdoc., School of Economics\n\n\n\n2010 Seoul National University (Seoul · South Korea) - Ph.D. School of Economics - Title: “Three Essays on Evolutionary Game Theory and Its Economic Applications”\n1997 Seoul National University - M.A. School of Economics\n1995 Seoul National University - B.A. School of Economics\n\n\n\n\n\n2009 Jun Sok Huhh. “The Evolution of PC bang Culture in Korea (Chapter 7).” Gaming Cultures and Place in Asia-Pacific [edited by Larissa Hjorth, Dean Chan]. Routledge.\n2006 Jun Sok Huhh. 2006. Business of Fun–Economics of computer games industry 재미의 비즈니스. ChekSeSang. [Korean language]\n\n\n\n2017 Jun Sok Huhh and Jeong Wook Byun. “North Korea’s Nuclear Weapon Development and South Korea’s Strategic Reaction: A Signaling Game Approach.” Ehwa Journal of Social Sciences 33(1): 107–142. [Korean language]\n2012 Jun Sok Huhh and Jung-Kyu Choi. 2012. “The Decay in Contributions in a Public Goods Game: Learning Hypothesis, Strategy Hypothesis and Reciprocity Hypothesis Revisited.” Journal of Econometric Theory and Econometrics 23(2):165–186. [Korean language]\n2008 Jun Sok Huhh. 2008. “Culture and Business of PC Bangs in Korea.” Games and Culture 3(1):26–37.\n\n\n\n\nProficient Python, R, Mathematica, \\(\\rm \\LaTeX\\), markdown\nFamiliar NetLogo, Docker, Kubernetes\n\n\n\n\n\n\nSuwon-si, South Korea, http://en.hanall.co.kr/\n\nscRNA-seq data analysis\n\n\n\n\nHwaseong-si, South Korea, http://www.panolos.com/\n\nin silico protein designer\nPurification process developer\n\n\n\n\nYongin-si, South Korea, http://www.ckdpharm.com/\n\nProtein engineering\nPOC study(HPLC analysis, PK)\nPurification process developer\n\n\n\n\nYongin-si, South Korea, http://www.mogam.re.kr/\n\nProtein engineering\nPOC study (HPLC analysis, PK, PD)\nConjugated protein (ADC, PEGylation)\n\n\n\n\nCheongju-si, South Korea, https://www.kbsi.re.kr/\n\nHigh-throughput Mass spectrometry data analysis\nCharts and report design for a small medical device company\n\n\n\n\nCheongju-si, South Korea, http://www.skbioland.com/\nSupport research and development group for diagnosis of HIV\n\nTesting HIV detection kits\n\n\n\n\n\n\n\nPOSTECH, Pohang\n\n\n\nChungbuk National Univ, Cheongju"
  },
  {
    "objectID": "resume.html#currently",
    "href": "resume.html#currently",
    "title": "Resume",
    "section": "",
    "text": "NCSOFT 엔씨 (South Korea), Lead of Data Center\n\n\nData analytics, Economics\n\n\n\n\nEconometric analysis on online gaming behaviors\nReal-money trading in online games\nGame theory"
  },
  {
    "objectID": "resume.html#employment",
    "href": "resume.html#employment",
    "title": "Resume",
    "section": "",
    "text": "2019.02 -- present NCSOFT, Data Center (Seongnam Gyeonggi · South Korea) - Lead (executive director) - managing the group of data scientists\n2018.03 -- 2019.01 NCSOFT, I&I Division - Lead\n2014.08 -- 2018.03 NCSOFT, R&I Team - Lead\n2013.05 -- 2014.07 KISDI\\(^*\\) (Jinchun Chungchungbuk · South Korea) - \\(*\\) Korea Information Society Development Institute 정보통신정책연구원 - Senior Researcher (Telecommunication Unit)\n2012.01 -- 2013.03 FourThirtyThree 네시삼십삼분 (Seoul · South Korea) - Data Analyst, Consultant\n2011.03 -- 2012.02 Seoul National University 서울대학교 (Seoul · South Korea) - Postdoc., School of Economics"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Resume",
    "section": "",
    "text": "2010 Seoul National University (Seoul · South Korea) - Ph.D. School of Economics - Title: “Three Essays on Evolutionary Game Theory and Its Economic Applications”\n1997 Seoul National University - M.A. School of Economics\n1995 Seoul National University - B.A. School of Economics"
  },
  {
    "objectID": "resume.html#selected-publications",
    "href": "resume.html#selected-publications",
    "title": "Resume",
    "section": "",
    "text": "2009 Jun Sok Huhh. “The Evolution of PC bang Culture in Korea (Chapter 7).” Gaming Cultures and Place in Asia-Pacific [edited by Larissa Hjorth, Dean Chan]. Routledge.\n2006 Jun Sok Huhh. 2006. Business of Fun–Economics of computer games industry 재미의 비즈니스. ChekSeSang. [Korean language]\n\n\n\n2017 Jun Sok Huhh and Jeong Wook Byun. “North Korea’s Nuclear Weapon Development and South Korea’s Strategic Reaction: A Signaling Game Approach.” Ehwa Journal of Social Sciences 33(1): 107–142. [Korean language]\n2012 Jun Sok Huhh and Jung-Kyu Choi. 2012. “The Decay in Contributions in a Public Goods Game: Learning Hypothesis, Strategy Hypothesis and Reciprocity Hypothesis Revisited.” Journal of Econometric Theory and Econometrics 23(2):165–186. [Korean language]\n2008 Jun Sok Huhh. 2008. “Culture and Business of PC Bangs in Korea.” Games and Culture 3(1):26–37."
  },
  {
    "objectID": "resume.html#technical-skills",
    "href": "resume.html#technical-skills",
    "title": "Resume",
    "section": "",
    "text": "Proficient Python, R, Mathematica, \\(\\rm \\LaTeX\\), markdown\nFamiliar NetLogo, Docker, Kubernetes"
  },
  {
    "objectID": "resume.html#work-experience",
    "href": "resume.html#work-experience",
    "title": "Resume",
    "section": "",
    "text": "Suwon-si, South Korea, http://en.hanall.co.kr/\n\nscRNA-seq data analysis\n\n\n\n\nHwaseong-si, South Korea, http://www.panolos.com/\n\nin silico protein designer\nPurification process developer\n\n\n\n\nYongin-si, South Korea, http://www.ckdpharm.com/\n\nProtein engineering\nPOC study(HPLC analysis, PK)\nPurification process developer\n\n\n\n\nYongin-si, South Korea, http://www.mogam.re.kr/\n\nProtein engineering\nPOC study (HPLC analysis, PK, PD)\nConjugated protein (ADC, PEGylation)\n\n\n\n\nCheongju-si, South Korea, https://www.kbsi.re.kr/\n\nHigh-throughput Mass spectrometry data analysis\nCharts and report design for a small medical device company\n\n\n\n\nCheongju-si, South Korea, http://www.skbioland.com/\nSupport research and development group for diagnosis of HIV\n\nTesting HIV detection kits"
  },
  {
    "objectID": "resume.html#education-1",
    "href": "resume.html#education-1",
    "title": "Resume",
    "section": "",
    "text": "POSTECH, Pohang\n\n\n\nChungbuk National Univ, Cheongju"
  },
  {
    "objectID": "posts/learn_jupyter.html",
    "href": "posts/learn_jupyter.html",
    "title": "Jupyter notebook 소개",
    "section": "",
    "text": "원래 ipython는 파이썬을 위한 향상된 대화형 커맨드라인 콘솔입니다. Jupyter notebook은 그것에서 보다 발전된 형태로 코딩과 문서화를 동시에 해서 생산성을 극대화 하는 도구입니다.\n\nprint(\"Hello!\")\n\nHello!\n\n\n\n\n파일 시스템과 상호작용을 할 수 있는 명령어로 % 기호로 시작합니다. 현재 디렉토리 위치를 출력해 보겠습니다.\n\n%pwd\n\n'/home/partrita/Documents/blog/partrita.github.io/posts'\n\n\n더 많은 매직 명령어는 %lsmagic으로 확인 할 수 있고, 각 명령어에 ?를 추가하면 추가 정보를 보여줍니다.\n\n%lsmagic\n\nAvailable line magics:\n%alias  %alias_magic  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %popd  %pprint  %precision  %profile  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n\nAvailable cell magics:\n%%!  %%HTML  %%SVG  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n\nAutomagic is ON, % prefix IS NOT needed for line magics.\n\n\n\n\n\n자동완성은 믿을 수 없을 정도로 아주 유용한 기능입니다. 코딩을 하면서 모든 것을 타이핑하는것보다 tab키를 누르면 알아서 완성해주는 기능입니다."
  },
  {
    "objectID": "posts/learn_jupyter.html#매직-명령어magic-commands",
    "href": "posts/learn_jupyter.html#매직-명령어magic-commands",
    "title": "Jupyter notebook 소개",
    "section": "",
    "text": "파일 시스템과 상호작용을 할 수 있는 명령어로 % 기호로 시작합니다. 현재 디렉토리 위치를 출력해 보겠습니다.\n\n%pwd\n\n'/home/partrita/Documents/blog/partrita.github.io/posts'\n\n\n더 많은 매직 명령어는 %lsmagic으로 확인 할 수 있고, 각 명령어에 ?를 추가하면 추가 정보를 보여줍니다.\n\n%lsmagic\n\nAvailable line magics:\n%alias  %alias_magic  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %popd  %pprint  %precision  %profile  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n\nAvailable cell magics:\n%%!  %%HTML  %%SVG  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n\nAutomagic is ON, % prefix IS NOT needed for line magics."
  },
  {
    "objectID": "posts/learn_jupyter.html#자동완성-tab-completion",
    "href": "posts/learn_jupyter.html#자동완성-tab-completion",
    "title": "Jupyter notebook 소개",
    "section": "",
    "text": "자동완성은 믿을 수 없을 정도로 아주 유용한 기능입니다. 코딩을 하면서 모든 것을 타이핑하는것보다 tab키를 누르면 알아서 완성해주는 기능입니다."
  },
  {
    "objectID": "posts/learn_jupyter.html#seaborn-시각화",
    "href": "posts/learn_jupyter.html#seaborn-시각화",
    "title": "Jupyter notebook 소개",
    "section": "Seaborn 시각화",
    "text": "Seaborn 시각화\nseaborn은 사용하기 쉬운 발전된 기능을 제공 합니다.\n\n# 예제에 사용될 데이터를 읽어오자\ndf = sns.load_dataset('iris')\ndf.head() # 데이터의 모양을 확인\n\n\n\n\n\n\n\n\nsepal_length\nsepal_width\npetal_length\npetal_width\nspecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n\n\n\n\n\n사용한 데이터셋은 붓꽃(iris) 의 3가지 종(setosa, versicolor, virginica)에 대해 꽃받침(sepal)과 꽃잎(petal)의 넓이와 길이를 정리한 데이터입니다.\n\n위 그림을 참고하시면 이해가 되실 겁니다.\n\n# pair plot을 그려본다\nsns.pairplot(df, hue = 'species', size = 2.5)\n\n\n\n\n각각의 붓꽃종에 따라 꽃받침(sepal)과 꽃잎(petal)에 어떠한 연관성이 있는 지 확인 할 수 있습니다. 예를 들면 꽃잎의 길이가 길면 넓이도 넓어지는것은 모든종에서 연관관계가 있는 것을 볼수 있습니다."
  },
  {
    "objectID": "posts/python_StatisticalTesting.html",
    "href": "posts/python_StatisticalTesting.html",
    "title": "파이썬 statsmodels로 통계분석",
    "section": "",
    "text": "통계적 추론이라는 것은 제한된 실험 데이터에서 얻은 결과를 모집단에도 적용하려는 것입니다. 이번 포스트에서는 통계적 추론에 사용되는 검정법을 배워봅니다."
  },
  {
    "objectID": "posts/python_StatisticalTesting.html#순열-검정을-통한-ab-검정",
    "href": "posts/python_StatisticalTesting.html#순열-검정을-통한-ab-검정",
    "title": "파이썬 statsmodels로 통계분석",
    "section": "1.1. 순열 검정을 통한 A/B 검정",
    "text": "1.1. 순열 검정을 통한 A/B 검정\n\n순열검정(permutaion test): 두 개 이상의 표본을 함께 결합하여 관측값들을 무작위로 재표본으로 추출하는 과정을 말한다.\n\n파이썬에서 순열 검정을 구현하기 위해 아래와 같이 perm_fun 함수를 정의합니다.\n\n# Permutation test example with stickiness\ndef perm_fun(x, nA, nB):\n    n = nA + nB\n    idx_B = set(random.sample(range(n), nB))\n    idx_A = set(range(n)) - idx_B\n    return x.loc[idx_B].mean() - x.loc[idx_A].mean()\n    \nnA = session_times[session_times.Page == 'Page A'].shape[0]\nnB = session_times[session_times.Page == 'Page B'].shape[0]\nprint(perm_fun(session_times.Time, nA, nB))\n\n24.23809523809524\n\n\n단 한번의 계산을 통해서 24초라는 차이가 발생하였습니다. 계산을 반복해서 페이지A와 페이지B 사이의 시간 차이에 대한 도수 분포표를 그려봅시다.\n\nrandom.seed(1)\nperm_diffs = [perm_fun(session_times.Time, nA, nB) for _ in range(1000)]\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.hist(perm_diffs, bins=11, rwidth=0.9)\nax.axvline(x = mean_b - mean_a, color='black', lw=2)\nax.text(50, 190, 'Observed\\ndifference', bbox={'facecolor':'white'})\nax.set_xlabel('Session time differences (in seconds)')\nax.set_ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n위 그림에서 수직선은 관측된 차이입니다. 이것을 통해 순열 검정에서 가끔 실제 관찰된 차이를 넘어가는 것을 알 수 있습니다. 그렇다면 어느정도의 확률로 그런 일이 벌어질까요?\n\nprint(np.mean(perm_diffs &gt; mean_b - mean_a))\n\n0.121\n\n\n답은 12.1% 입니다. 이것을 통해 페이지A와 페이지B의 차이인 36초가 통계적으로 봤을때는 차이가 없어도 약 12% 확률로 발생할 수 있다는 결론을 얻었습니다."
  },
  {
    "objectID": "posts/python_StatisticalTesting.html#t-test를-사용한-ab-검정",
    "href": "posts/python_StatisticalTesting.html#t-test를-사용한-ab-검정",
    "title": "파이썬 statsmodels로 통계분석",
    "section": "1.1.2. t-Test를 사용한 A/B 검정",
    "text": "1.1.2. t-Test를 사용한 A/B 검정\n\nt-테스트(t-test) 또는 t-검정 또는 스튜던트 t-테스트(Student’s t-test)는 검정통계량이 귀무가설 하에서 t-분포를 따르는 통계적 가설 검정법이다. t-테스트는 일반적으로 검정통계량이 정규 분포를 따르며 분포와 관련된 스케일링 변숫값들이 알려진 경우에 사용한다. 이때 모집단의 분산과 같은 스케일링 항을 알 수 없으나, 이를 데이터를 기반으로 한 추정값으로 대체하면 검정통계량은 t-분포를 따른다. 예를 들어 t-테스트를 사용하여 두 데이터 세트(집단)의 평균이 서로 유의하게 다른지 여부를 판별할 수 있다. -wiki\n\n파이썬에서는 ttest_ind 함수를 사용하면 손쉽게 구해볼 수 있습니다.\n\nres = stats.ttest_ind(session_times[session_times.Page == 'Page A'].Time, \n                      session_times[session_times.Page == 'Page B'].Time,\n                      equal_var=False)\nprint(f'p-value for single sided test: {res.pvalue / 2:.4f}')\n\np-value for single sided test: 0.1408\n\n\n결과 값이 앞서 구한 순열 검정의 확률인 12%과 유사한 수치인 14%임을 확인 할 수 있습니다. 컴퓨터가 보급되기 전에 순열 검정은 실용적이지 않았고 그래서 통계학자들에게 t-Test가 널리 사용되었습니다.\n\ntstat, pvalue, df = sm.stats.ttest_ind(\n    session_times[session_times.Page == 'Page A'].Time, \n    session_times[session_times.Page == 'Page B'].Time,\n    usevar='unequal', alternative='smaller')\nprint(f'p-value: {pvalue:.4f}')\n\np-value: 0.1408"
  },
  {
    "objectID": "posts/python_StatisticalTesting.html#p-value-구하기",
    "href": "posts/python_StatisticalTesting.html#p-value-구하기",
    "title": "파이썬 statsmodels로 통계분석",
    "section": "2.1. P-Value 구하기",
    "text": "2.1. P-Value 구하기\np-value는 순열 검정에서 얻은 결과 중에 관찰된 차이와 같거나 더 큰 차이를 보이는 경우의 비율이라고 할 수 있기에 다음과 같이 추정할 수 있습니다.\n\nprint(np.mean([diff &gt; obs_pct_diff for diff in perm_diffs]))\n\n0.332\n\n\n예상한 것처럼 30%의 확률로 우연에 의해서 나타날 수 있는 차이였습니다. 따라서 페이지A와 페이지B의 차이는 통계적으로 유의미하지 않다고 말할 수 있겠습니다."
  },
  {
    "objectID": "posts/python_StatisticalTesting.html#순열검정을-통한-one-way-anova",
    "href": "posts/python_StatisticalTesting.html#순열검정을-통한-one-way-anova",
    "title": "파이썬 statsmodels로 통계분석",
    "section": "3.1. 순열검정을 통한 one-way ANOVA",
    "text": "3.1. 순열검정을 통한 one-way ANOVA\n파이썬에서는 다음 코드를 사용해 순열 검정을 통해 ANOVA 분석을 진행할 수 있습니다.\n\nobserved_variance = four_sessions.groupby('Page').mean().var()[0]\nprint('Observed means:', four_sessions.groupby('Page').mean().values.ravel())\nprint('Variance:', observed_variance)\n# Permutation test example with stickiness\ndef perm_test(df):\n    df = df.copy()\n    df['Time'] = np.random.permutation(df['Time'].values)\n    return df.groupby('Page').mean().var()[0]\n    \nprint(perm_test(four_sessions))\n\nObserved means: [172.8 182.6 175.6 164.6]\nVariance: 55.426666666666655\n57.02666666666678\n\n\n\nrandom.seed(1)\nperm_variance = [perm_test(four_sessions) for _ in range(3000)]\nprint('Pr(Prob)', np.mean([var &gt; observed_variance for var in perm_variance]))\n\nfig, ax = plt.subplots(figsize=(5, 5))\nax.hist(perm_variance, bins=11, rwidth=0.9)\nax.axvline(x = observed_variance, color='black', lw=2)\nax.text(60, 200, 'Observed\\nvariance', bbox={'facecolor':'white'})\nax.set_xlabel('Variance')\nax.set_ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()\n\nPr(Prob) 0.07766666666666666\n\n\n\n\n\nPr(Prob)의 값은 p-value이며 결과는 0.07입니다. 통상적인 임계 p-value 값인 0.05이상임으로 네 페이지간의 차이가 우연히 발생할 수 있다고 결론 내릴 수 있습니다."
  },
  {
    "objectID": "posts/python_StatisticalTesting.html#f-통계량을-통한-one-way-anova",
    "href": "posts/python_StatisticalTesting.html#f-통계량을-통한-one-way-anova",
    "title": "파이썬 statsmodels로 통계분석",
    "section": "3.2. F-통계량을 통한 one-way ANOVA",
    "text": "3.2. F-통계량을 통한 one-way ANOVA\nF-통계량은 잔차 오류에 인한 분산과 그룹 평균의 분산에 대한 비율을 기초로 합니다. 비율이 높으면 통계적으로 유의미 하다고 할 수 있고 이를 토대로 p-value를 계산할 수 있습니다.\n\nmodel = smf.ols('Time ~ Page', data=four_sessions).fit()\n                \naov_table = sm.stats.anova_lm(model)\nprint(aov_table)\n\n            df  sum_sq     mean_sq         F    PR(&gt;F)\nPage       3.0   831.4  277.133333  2.739825  0.077586\nResidual  16.0  1618.4  101.150000       NaN       NaN\n\n\ndf는 자유도, sum_sq는 제곱합, mean_sq는 평균제곱, F는 F-통계량을 나타냅니다.\n\nres = stats.f_oneway(four_sessions[four_sessions.Page == 'Page 1'].Time, \n                     four_sessions[four_sessions.Page == 'Page 2'].Time,\n                     four_sessions[four_sessions.Page == 'Page 3'].Time,\n                     four_sessions[four_sessions.Page == 'Page 4'].Time)\nprint(f'F-Statistic: {res.statistic / 2:.4f}')\nprint(f'p-value: {res.pvalue / 2:.4f}')\n\nF-Statistic: 1.3699\np-value: 0.0388\n\n\nF-통계량을 사용한 방법은 p-value 값이 더 적게나와 임계값인 0.05 이하입니다. 그러나 ANOVA 분석의 p-value가 낮게 나왔다고 해서 모든 그룹에서 통계적으로 차이가 있다고 할 수는 없습니다. 추가적인 Ad hoc 분석을 진행해 어떤 그룹에서 차이가 있는지 확인해보아야 합니다."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Log.42",
    "section": "",
    "text": "Welcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\nqmd\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2023\n\n\n\n\n\n\n  \n\n\n\n\n파이썬 statsmodels로 통계분석\n\n\n\n\n\n\n\npython\n\n\nstatstics\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2023\n\n\nTaeyoon kim\n\n\n\n\n\n\n  \n\n\n\n\n파이썬 통계분석하기\n\n\n\n\n\n\n\npython\n\n\nstatstics\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2023\n\n\nTaeyoon kim\n\n\n\n\n\n\n  \n\n\n\n\nJupyter notebook 소개\n\n\n\n\n\n\n\nnews\n\n\nqmd\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2023\n\n\nTaeyoon kim\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "이 블로그는 제가 생물학자 겸 개발자 로서 흥미롭고 유용하다고 생각되는 것을 올리고 있어요. 과학자로서의 삶 은 흥미로운 것들로 가득찬 모험이어야 합니다. 그래서 뒤죽박죽 엉망처럼 보일 수 있지만 나름 공을 들여 정리한 것들 입니다.\n**‘과학자는 유용(有用)하게 쓸 수 있다고 해서 연구하는 것이 아니다. 그 속에서 희열을 느끼기 때문이다.’** \n-- Henri Poincaré"
  },
  {
    "objectID": "about.html#짧은-소개",
    "href": "about.html#짧은-소개",
    "title": "About",
    "section": "",
    "text": "이 블로그는 제가 생물학자 겸 개발자 로서 흥미롭고 유용하다고 생각되는 것을 올리고 있어요. 과학자로서의 삶 은 흥미로운 것들로 가득찬 모험이어야 합니다. 그래서 뒤죽박죽 엉망처럼 보일 수 있지만 나름 공을 들여 정리한 것들 입니다.\n**‘과학자는 유용(有用)하게 쓸 수 있다고 해서 연구하는 것이 아니다. 그 속에서 희열을 느끼기 때문이다.’** \n-- Henri Poincaré"
  },
  {
    "objectID": "about.html#무계획이-계획",
    "href": "about.html#무계획이-계획",
    "title": "About",
    "section": "무계획이 계획",
    "text": "무계획이 계획\n습관적으로 일을 미루는 나의 행동을 정당하기 위한 변명입니다. 언젠가 하겠다는 생각은 늘해왔지만 글을 쓰는 일은 하기 싫은 일입니다. 아무리 적어도 다시 읽어보면 내용이 형편 없기 때문입니다. 그래도 조금이나마 글쓰는 힘을 키우기 위해 이 블로그를 만들었습니다. 그래서 큰 목표와 목적 없이 일벌레와 게으름뱅이 과학자 사이에서 내 마음대로 조금 유익한 일을 하려고 합니다."
  },
  {
    "objectID": "about.html#작업-환경",
    "href": "about.html#작업-환경",
    "title": "About",
    "section": "작업 환경",
    "text": "작업 환경\n제가 사용하는 환경에 대해서 간략히 적어볼게요.\n\n사용하는 OS는 Windows [#]_ 와 Linux [#]_ 입니다. Linux 중 에서도 Ubuntu를 좀 더 선호했었죠. 그런데 최근에는 더 이쁜 Solus &lt;https://getsol.us/home/&gt;_ 를 쓰고 있습니다.\n코딩할 때는 Visual studio code &lt;https://code.visualstudio.com/&gt;_ 를 쓰고, 파이펫팅 할 때는 Eppendorf 파이펫 &lt;https://www.pipette.com/eppendorfpipettes&gt;_ 을 씁니다, 가볍거든요.\n\n주로 쓰는 프로그래밍 언어는 Python &lt;https://www.python.org/&gt;_ 이고 R &lt;https://www.r-project.org/&gt;_ 과 Julia &lt;https://julialang.org/&gt;_ 를 공부하고 있습니다.\n이 블로그는 Github 에서 무료 호스팅되고, Static site generator 인 Nikola 를 사용했습니다."
  },
  {
    "objectID": "about.html#왜-블로그를-하는가",
    "href": "about.html#왜-블로그를-하는가",
    "title": "About",
    "section": "왜 블로그를 하는가?",
    "text": "왜 블로그를 하는가?\n오래전부터(아마도 2006년) 존재감 없는 블로그를 만들어왔습니다. 제가 기억하는 선에서 한번 나열해보죠.\n\nhttp://netsphere.codex.kr/ : 호스팅 업체가 망해버렸습니다.\nhttp://partrita.posterous.com/ : 서비스가 종료되었습니다.\nhttps://partrita.blogspot.kr/ : 구글검색어 노출에 유리 [#]_ 했지만, 제약이 많아서 워드프레스로 이사\nhttps://partrita.wordpress.com/ : 처음에는 설치형을 사용하다. 무료호스팅을 제공하는 wordpress.com 으로 이사했습니다.\nhttps://partrita.github.io/ : PHP(워드프레스)는 너무 올드한 것 같고 핫한 깃헙으로 이전했습니다.\n\n여러번 이전을 하면서 과거의 글은 소실(나중에 보니 부끄러워 삭제)되었네요. 뭐 괜찮습니다. 제가 블로그를 하는 이유도 명확하지 않거든요. 그냥 재미로 하는 겁니다."
  },
  {
    "objectID": "about.html#nikola-블로그",
    "href": "about.html#nikola-블로그",
    "title": "About",
    "section": "Nikola 블로그",
    "text": "Nikola 블로그\nStatic site generator 중에 가장 유명한건 Jekyll &lt;https://jekyllrb-ko.github.io/&gt;_ 입니다. 저도 처음에는 Jekyll을 사용했습니다. 그러다 Nikola &lt;https://getnikola.com/&gt;_ 를 발견했고 Jupyter notebook 포스팅을 제공 한다는 사실을 알았죠. 저는 주로 Jupyter notebook에 코딩을 하기 때문에 바로 Nikola로 갈아 탔습니다.\n장점: - Jupyter notebook 포맷(ipynb) 변경이 필요하지 않습니다. - Python으로 작성되어 있어 가독성이 좋고 (내가) 편집이 쉽죠. - 여러가지 편리한 명령어를 지원합니다. 예를 들면 github_deploy 로 한방에 올리기!\n단점: - 사용자 수가 적어 정보가 적고 앞으로도 늘어날 것 같지는 않습니다. - 테마는 많이 부족합니다.\n저처럼 Jupyter notebook으로 블로그 포스트를 작성하고 싶으신 분들은 설치 가이드 &lt;http://partrita.github.io/posts/nikola-for-jupyer-blog/&gt;_ 를 참고 하세요."
  },
  {
    "objectID": "about.html#라즈베리파이-_",
    "href": "about.html#라즈베리파이-_",
    "title": "About",
    "section": "라즈베리파이 [#]_",
    "text": "라즈베리파이 [#]_\n최근에 웹 프로그래밍에 관심이 생겨서 개인프로젝트용으로 서버로 사용하고 있습니다. 접속 주소는 http://partrita.iptime.org &lt;http://partrita.iptime.org/&gt;_ 입니다.\n\n라즈베리안 OS를 사용 중입니다.\n간이 NAS로 더 유용하게 쓰고 있습니다.\n\n라즈베리에 대해서도 정리해서 올려놓도록 하겠습니다."
  },
  {
    "objectID": "about.html#저작권에-대해",
    "href": "about.html#저작권에-대해",
    "title": "About",
    "section": "저작권에 대해",
    "text": "저작권에 대해\n이 곳에 올리는 글의 대부분은 저의 독창 적인 내용이 아닙니다. 제가 다른 곳(주로 인터넷)에서 얻은 정보들을 제멋대로 편집 해놓은 것이지요. 그래서 제가 쓴 글에 저작권 보호를 받는 자료가 포함되어 있을 수도 있어요. 만약 저작권을 침해한 것이 있다면 이메일 [#]_ 으로 연락 주시면 바로 처리하겠습니다.\n\n.. [#] 거의 반강제적으로 사용하는거라 좋아하진 않습니다. .. [#] 리누스 토발즈가 개발한 컴퓨터 운영 체제. .. [#] 블로거 서비스가 구글에 인수되었습니다. .. [#] 영국 라즈베리 파이(Raspberry Pi) 재단에서 만든 초소형/초저가 PC .. [#] partrita@gmail.com"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nUniversity of California, San Diego | San Diego, CA PhD in Mathematics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nWengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Spet 2012 - April 2018\n\n\nC.V.\nBrief | Long"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/python_Statistics.html",
    "href": "posts/python_Statistics.html",
    "title": "파이썬 통계분석하기",
    "section": "",
    "text": "통계 계산을 위한 프로그래밍 언어에 R 프로그래밍 언어(줄여서 R)가 있는데, 왜 파이썬을 써야 할까요?\nR은 문법 자체부터 통계에 특화되어 있고 여러가지 통계분석을 할 수 있습니다. 그럼에도 불구하고 제가 파이썬을 통계분석에 사용하는 이유는 간단합니다. 파이썬은 보다 범용적인 언어이고 라이브러리가 풍부해서 제가 원하는 기능은 거의 이미 다 있기 때문이죠.\n\n\n여기, brain_size 라는 데이터를 살펴 보겠습니다.\n\n# 필요한 라이브러리를 불러옵니다.\n%matplotlib inline\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n\n\nbrain_size 데이터는 Willerman이 1991년에 사람의 뇌 크기와 무게, 그리고 IQ에 대하여 측정한 값입니다. 범주형의 데이터와 수치형 데이터로 구성 되어 있죠.\nPandas의 read_csv 기능을 이용해 데이터프레임을 만들어 보겠습니다.\n\ndf = pd.read_csv('http://www.scipy-lectures.org/_downloads/brain_size.csv',\n                 sep = ';', index_col= 0, na_values='.')\ndf.head() # 상단의 5개의 데이터 확인하기\n\n\n\n\n\n\n\n\nGender\nFSIQ\nVIQ\nPIQ\nWeight\nHeight\nMRI_Count\n\n\n\n\n1\nFemale\n133\n132\n124\n118.0\n64.5\n816932\n\n\n2\nMale\n140\n150\n124\nNaN\n72.5\n1001121\n\n\n3\nMale\n139\n123\n150\n143.0\n73.3\n1038437\n\n\n4\nMale\n133\n129\n128\n172.0\n68.8\n965353\n\n\n5\nFemale\n137\n132\n134\n147.0\n65.0\n951545\n\n\n\n\n\n\n\n간단히 살펴보면, 총 40명의 사람들의 성별, IQ, 몸무게, 키 그리고 MRI_count(total pixel Count from the 18 MRI scans) 값이 측정되어 있습니다. IQ의 경우 3종류로 세분화 되어있는데 각각을 알아 보면 아래와 같습니다.\n\nFull Scale Intelligence Quotient (FSIQ) : VIQ와 PIQ의 종합적인 수치입니다\nVerbal IQ (VIQ) : 언어적인 측면을 측정합니다.\nPerformance IQ (PIQ) : 논리, 계산적인 측면을 측정\n\n\n\n\npandas에서는 간단하게 평균값과 표준편차등을 계산해주는 기능이 있습니다.\ndescribe() 함수를 사용하면 모든 열에 대한 설명통계값을 보여줍니다.\n\n# padas 에서 제공하는 설명 통계\ndf.describe()\n\n\n\n\n\n\n\n\nFSIQ\nVIQ\nPIQ\nWeight\nHeight\nMRI_Count\n\n\n\n\ncount\n40.000000\n40.000000\n40.00000\n38.000000\n39.000000\n4.000000e+01\n\n\nmean\n113.450000\n112.350000\n111.02500\n151.052632\n68.525641\n9.087550e+05\n\n\nstd\n24.082071\n23.616107\n22.47105\n23.478509\n3.994649\n7.228205e+04\n\n\nmin\n77.000000\n71.000000\n72.00000\n106.000000\n62.000000\n7.906190e+05\n\n\n25%\n89.750000\n90.000000\n88.25000\n135.250000\n66.000000\n8.559185e+05\n\n\n50%\n116.500000\n113.000000\n115.00000\n146.500000\n68.000000\n9.053990e+05\n\n\n75%\n135.500000\n129.750000\n128.00000\n172.000000\n70.500000\n9.500780e+05\n\n\nmax\n144.000000\n150.000000\n150.00000\n192.000000\n77.000000\n1.079549e+06\n\n\n\n\n\n\n\nIQ의 평균값은 113이군요. 몸무게는 kg으로 변환하면 약 70kg쯤 됩니다.\n\n\n\n전체적인 데이터의 양상을 보기에는 시각화가 중요합니다. 파이썬에서는 간단하게 산포 행렬(sactter matrix)를 그려 볼 수 있습니다.\n먼저 키와 몸무게, MRI_count 간의 상관관계를 보겠습니다.\n\n# Plotting data\nfrom pandas.plotting import scatter_matrix\n# 키와 몸무게, MRI_count \nscatter_matrix(df[['Weight', 'Height', 'MRI_Count']])  \n\narray([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A1D2B70&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A443668&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A47E588&gt;],\n       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A4B9588&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A56D4A8&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A56D4E0&gt;],\n       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A5DC978&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A614EB8&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A643B70&gt;]], dtype=object)\n\n\n\n\n\n키와 몸무계는 서로 연관이 있는듯 하고 나머지는 그다지 서로 연관이 없어 보입니다.\n그 다음으로는 여러 IQ 수치간에 상관관계를 알아 보죠.\n\nscatter_matrix(df[['PIQ', 'VIQ', 'FSIQ']])\n\narray([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A9AD6A0&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A9F34A8&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AA2E3C8&gt;],\n       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AA64358&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AAA0358&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AAA0390&gt;],\n       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AB01EB8&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AB3DEB8&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AB72EB8&gt;]], dtype=object)\n\n\n\n\n\n당연하지만, FSIQ는 VIQ, PIQ 각각과 연관성이 있어 보입니다. VIQ와 PIQ간에는 애매하게 연관성이 없어 보이네요. FSIQ의 히스토그램에서는 100 - 125 사이에는 데이터가 없는 것을 확인 할 수 있습니다."
  },
  {
    "objectID": "posts/python_Statistics.html#예를-들어봅시다.",
    "href": "posts/python_Statistics.html#예를-들어봅시다.",
    "title": "파이썬 통계분석하기",
    "section": "",
    "text": "여기, brain_size 라는 데이터를 살펴 보겠습니다.\n\n# 필요한 라이브러리를 불러옵니다.\n%matplotlib inline\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/python_Statistics.html#csv-파일-읽어오기",
    "href": "posts/python_Statistics.html#csv-파일-읽어오기",
    "title": "파이썬 통계분석하기",
    "section": "",
    "text": "brain_size 데이터는 Willerman이 1991년에 사람의 뇌 크기와 무게, 그리고 IQ에 대하여 측정한 값입니다. 범주형의 데이터와 수치형 데이터로 구성 되어 있죠.\nPandas의 read_csv 기능을 이용해 데이터프레임을 만들어 보겠습니다.\n\ndf = pd.read_csv('http://www.scipy-lectures.org/_downloads/brain_size.csv',\n                 sep = ';', index_col= 0, na_values='.')\ndf.head() # 상단의 5개의 데이터 확인하기\n\n\n\n\n\n\n\n\nGender\nFSIQ\nVIQ\nPIQ\nWeight\nHeight\nMRI_Count\n\n\n\n\n1\nFemale\n133\n132\n124\n118.0\n64.5\n816932\n\n\n2\nMale\n140\n150\n124\nNaN\n72.5\n1001121\n\n\n3\nMale\n139\n123\n150\n143.0\n73.3\n1038437\n\n\n4\nMale\n133\n129\n128\n172.0\n68.8\n965353\n\n\n5\nFemale\n137\n132\n134\n147.0\n65.0\n951545\n\n\n\n\n\n\n\n간단히 살펴보면, 총 40명의 사람들의 성별, IQ, 몸무게, 키 그리고 MRI_count(total pixel Count from the 18 MRI scans) 값이 측정되어 있습니다. IQ의 경우 3종류로 세분화 되어있는데 각각을 알아 보면 아래와 같습니다.\n\nFull Scale Intelligence Quotient (FSIQ) : VIQ와 PIQ의 종합적인 수치입니다\nVerbal IQ (VIQ) : 언어적인 측면을 측정합니다.\nPerformance IQ (PIQ) : 논리, 계산적인 측면을 측정"
  },
  {
    "objectID": "posts/python_Statistics.html#pandas-설명통계",
    "href": "posts/python_Statistics.html#pandas-설명통계",
    "title": "파이썬 통계분석하기",
    "section": "",
    "text": "pandas에서는 간단하게 평균값과 표준편차등을 계산해주는 기능이 있습니다.\ndescribe() 함수를 사용하면 모든 열에 대한 설명통계값을 보여줍니다.\n\n# padas 에서 제공하는 설명 통계\ndf.describe()\n\n\n\n\n\n\n\n\nFSIQ\nVIQ\nPIQ\nWeight\nHeight\nMRI_Count\n\n\n\n\ncount\n40.000000\n40.000000\n40.00000\n38.000000\n39.000000\n4.000000e+01\n\n\nmean\n113.450000\n112.350000\n111.02500\n151.052632\n68.525641\n9.087550e+05\n\n\nstd\n24.082071\n23.616107\n22.47105\n23.478509\n3.994649\n7.228205e+04\n\n\nmin\n77.000000\n71.000000\n72.00000\n106.000000\n62.000000\n7.906190e+05\n\n\n25%\n89.750000\n90.000000\n88.25000\n135.250000\n66.000000\n8.559185e+05\n\n\n50%\n116.500000\n113.000000\n115.00000\n146.500000\n68.000000\n9.053990e+05\n\n\n75%\n135.500000\n129.750000\n128.00000\n172.000000\n70.500000\n9.500780e+05\n\n\nmax\n144.000000\n150.000000\n150.00000\n192.000000\n77.000000\n1.079549e+06\n\n\n\n\n\n\n\nIQ의 평균값은 113이군요. 몸무게는 kg으로 변환하면 약 70kg쯤 됩니다."
  },
  {
    "objectID": "posts/python_Statistics.html#산포-행렬을-그려보겠습니다.",
    "href": "posts/python_Statistics.html#산포-행렬을-그려보겠습니다.",
    "title": "파이썬 통계분석하기",
    "section": "",
    "text": "전체적인 데이터의 양상을 보기에는 시각화가 중요합니다. 파이썬에서는 간단하게 산포 행렬(sactter matrix)를 그려 볼 수 있습니다.\n먼저 키와 몸무게, MRI_count 간의 상관관계를 보겠습니다.\n\n# Plotting data\nfrom pandas.plotting import scatter_matrix\n# 키와 몸무게, MRI_count \nscatter_matrix(df[['Weight', 'Height', 'MRI_Count']])  \n\narray([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A1D2B70&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A443668&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A47E588&gt;],\n       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A4B9588&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A56D4A8&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A56D4E0&gt;],\n       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A5DC978&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A614EB8&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A643B70&gt;]], dtype=object)\n\n\n\n\n\n키와 몸무계는 서로 연관이 있는듯 하고 나머지는 그다지 서로 연관이 없어 보입니다.\n그 다음으로는 여러 IQ 수치간에 상관관계를 알아 보죠.\n\nscatter_matrix(df[['PIQ', 'VIQ', 'FSIQ']])\n\narray([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A9AD6A0&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000A9F34A8&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AA2E3C8&gt;],\n       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AA64358&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AAA0358&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AAA0390&gt;],\n       [&lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AB01EB8&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AB3DEB8&gt;,\n        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000000AB72EB8&gt;]], dtype=object)\n\n\n\n\n\n당연하지만, FSIQ는 VIQ, PIQ 각각과 연관성이 있어 보입니다. VIQ와 PIQ간에는 애매하게 연관성이 없어 보이네요. FSIQ의 히스토그램에서는 100 - 125 사이에는 데이터가 없는 것을 확인 할 수 있습니다."
  },
  {
    "objectID": "posts/python_Statistics.html#sample-t-test",
    "href": "posts/python_Statistics.html#sample-t-test",
    "title": "파이썬 통계분석하기",
    "section": "1-sample T-test",
    "text": "1-sample T-test\n하나의 집단의 평균이 특정 기준보다 유의미하게 다른지 를 알아보는 분석 방법입니다. Student T-test이라고도 하는 1-sample T-test 를 사용하려면 scipy.stats.ttest_1samp() 함수를 사용하면 됩니다.\n\nfrom scipy import stats\n\n\n## Student’s t-test: the simplest statistical test\nstats.ttest_1samp(df['VIQ'], 0) \n# VIQ의 평균값이 0과 통계적으로 유의미하게 다른지 알아 보겠습니다.\n\nTtest_1sampResult(statistic=30.088099970849328, pvalue=1.3289196468728067e-28)\n\n\n간단하게 결론만 말하자면, p-value가 아주 낮음(10의 -28제곱) 으로 VIQ의 평균은 0이 아니라고 말할 수 있습니다."
  },
  {
    "objectID": "posts/python_Statistics.html#sample-t-test-1",
    "href": "posts/python_Statistics.html#sample-t-test-1",
    "title": "파이썬 통계분석하기",
    "section": "2-sample t-test",
    "text": "2-sample t-test\n서로 다른 두개의 그룹 간 평균의 차이가 유의미 한지 여부를 판단하기 위해 시행합니다. 2-sample t-test 는 scipy.stats.ttest_ind(): 함수를 사용합니다.\n예를 들어 여자의 VIQ와 남자의 VIQ의 평균은 통계적으로 차이가 있는지 알아 보겠습니다.\n\n# 여자의 VIQ\nfemale_viq = df[df['Gender'] == 'Female']['VIQ']\n# 남자의 VIQ\nmale_viq = df[df['Gender'] == 'Male']['VIQ']\n# 두개의 리스트를 가지고 t-test실행\nstats.ttest_ind(female_viq, male_viq) \n\nTtest_indResult(statistic=-0.77261617232750113, pvalue=0.44452876778583217)\n\n\np-value가 0.44로 아주 높게 나왔습니다. 따라서 기무가설이었던 남자와 여자의 VIQ 평균에는 차이가 있다. 는 기각되고 차이가 없다 라고 결론을 낼 수 있습니다."
  },
  {
    "objectID": "posts/python_Statistics.html#paired-tests",
    "href": "posts/python_Statistics.html#paired-tests",
    "title": "파이썬 통계분석하기",
    "section": "Paired tests:",
    "text": "Paired tests:\nPaired t-test는 동일한 집단에서의 반복적인 측정에 의한 차이를 비교하기 위해 사용됩니다. 예를 들면 커피가 수면시간에 미치는 영향을 보기 위해 커피를 마시지 않고 측정하고 커피를 마시고 측정한 데이터를 수집하여 사용합니다. &gt; 전제조건을 충족하기 위해서는 실험이 길어지는 단점이 있습니다"
  },
  {
    "objectID": "posts/python_Statistics.html#f-test",
    "href": "posts/python_Statistics.html#f-test",
    "title": "파이썬 통계분석하기",
    "section": "F-test",
    "text": "F-test\nF-test는 두 표본의 분산에 대한 차이가 통계적으로 유의한가를 판별하는 검정기법입니다. 다른 이름으로 var-test로도 불립니다.\n\nfrom statsmodels.formula.api import ols\n\nmodel = ols('VIQ ~ Gender + MRI_Count + Height', df).fit()\nprint(model.summary())\nprint(model.f_test([0, 1, 0, 0]))\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                    VIQ   R-squared:                       0.246\nModel:                            OLS   Adj. R-squared:                  0.181\nMethod:                 Least Squares   F-statistic:                     3.809\nDate:                Thu, 21 Dec 2017   Prob (F-statistic):             0.0184\nTime:                        15:34:54   Log-Likelihood:                -172.34\nNo. Observations:                  39   AIC:                             352.7\nDf Residuals:                      35   BIC:                             359.3\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==================================================================================\n                     coef    std err          t      P&gt;|t|      [0.025      0.975]\n----------------------------------------------------------------------------------\nIntercept        166.6258     88.824      1.876      0.069     -13.696     346.948\nGender[T.Male]     8.8524     10.710      0.827      0.414     -12.890      30.595\nMRI_Count          0.0002   6.46e-05      2.615      0.013    3.78e-05       0.000\nHeight            -3.0837      1.276     -2.417      0.021      -5.674      -0.494\n==============================================================================\nOmnibus:                        7.373   Durbin-Watson:                   2.109\nProb(Omnibus):                  0.025   Jarque-Bera (JB):                2.252\nSkew:                           0.005   Prob(JB):                        0.324\nKurtosis:                       1.823   Cond. No.                     2.40e+07\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 2.4e+07. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n&lt;F test: F=array([[ 0.68319608]]), p=0.4140878441244722, df_denom=35, df_num=1&gt;\n\n\nF test 결과, p-value 가 0.41로 아주 높게 나왔습니다. 따라서 기무가설을 기각하지 못합니다. 다시 말해 성별에 의한 VIQ 차이는 없다 라고 할 수 있습니다."
  },
  {
    "objectID": "posts/python_Statistics.html#시각화",
    "href": "posts/python_Statistics.html#시각화",
    "title": "파이썬 통계분석하기",
    "section": "시각화",
    "text": "시각화\n시각화를 하면 통계분석에 사용된 변수간의 상관관계를 손쉽게 확인할 수 있습니다. 아래 코드는 scatter_matrix를 그리는 방법입니다.\n\n# This plotting is useful to get an intuitions on the relationships between\n# our different variables\n\n# Fill in the missing values for Height for plotting\ndf['Height'].fillna(method='pad', inplace=True)\n\n# The parameter 'c' is passed to plt.scatter and will control the color\n# The same holds for parameters 'marker', 'alpha' and 'cmap', that\n# control respectively the type of marker used, their transparency and\n# the colormap\nscatter_matrix(df[['VIQ', 'MRI_Count', 'Height']],\n                        c=(df['Gender'] == 'Female'), marker='o',\n                        alpha=0.7)\n\nfig = plt.gcf()\nfig.suptitle(\"purple: male, yellow: female\", size=13)\n\nplt.show()"
  },
  {
    "objectID": "book.html",
    "href": "book.html",
    "title": "Book",
    "section": "",
    "text": "생명정보학 알고리즘\n파이썬으로 구현하는 생명정보학 알고리즘\n\n\n\n목차\n\n1장. 서문\n\n1.1 들어가며\n1.2 생명정보학이란?\n1.3 책의 구성\n\n2장. 파이썬 소개\n\n2.1 파이썬의 특징\n2.2 변수와 미리 정의된 함수\n2.3 파이썬 코드 작성하기\n2.4 파이썬 프로그램 개발\n2.5 객체지향 프로그래밍\n2.6 사전 정의된 클래스 및 메서드\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n3장. 세포 및 분자생물학의 기초\n\n3.1 세포: 생명의 기본 단위\n3.2 유전자 정보: 핵산\n3.3 유전자: 유전 정보의 이산 단위\n3.4 인간 유전체\n3.5 생물 자원 및 데이터베이스\n참고 문헌과 추가 자료\n연습 문제\n\n4장. 생물학적 서열의 기본적 처리\n\n4.1 생물학적 서열: 표현과 기본 알고리즘\n4.2 전사와 역상보\n4.3 번역\n4.4 가능성 있는 유전자 찾기: 오픈 리딩 프레임\n4.5 하나로 합체\n4.6 생물학 서열의 클래스\n4.7 바이오파이썬으로 서열 처리\n4.8 바이오파이썬의 서열 주석 객체\n연습 문제와 프로그래밍 프로젝트\n\n5장. 서열 데이터에서 패턴 찾기\n\n5.1 소개: 생명정보학에서 패턴 찾기의 중요성\n5.2 고정된 패턴을 찾는 단순한 알고리즘\n5.3 휴리스틱 알고리즘: 보이어-무어\n5.4 결정적 유한 오토마타\n5.5 정규표현식으로 유연한 패턴 찾기\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n6장. 쌍 서열 정렬\n\n6.1 소개: 서열 비교와 서열 정렬\n6.2 시각화 정렬: 점 도표\n6.3 서열 정렬의 최적화 문제\n6.4 전역 정렬을 위한 동적 프로그래밍 알고리즘\n6.5 지역 정렬을 위한 동적 프로그래밍 알고리즘\n6.6 서열 정렬의 특별한 경우\n6.7 바이오파이썬을 활용한 쌍 서열 정렬\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n7장. 데이터베이스에서 유사한 서열 찾기\n\n7.1 소개\n7.2 BLAST 알고리즘과 프로그램\n7.3 구현한 BLAST 이식\n7.4 바이오파이썬을 통한 BLAST 사용\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n8장. 다중 서열 정렬\n\n8.1 소개: 문제 정의와 복잡도\n8.2 다중 서열 정렬의 알고리즘 최적화 클래스\n8.3 점진적 정렬을 파이썬에서 구현\n8.4 바이오파이썬으로 정렬 다루기\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n9장. 계통학 분석\n\n9.1 소개: 문제 정의 및 연관성\n9.2 계통학적 분석을 위한 알고리즘 클래스\n9.3 파이썬으로 거리 기반 알고리즘 구현\n9.4 계통학 분석을 위한 바이오파이썬\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n10장. 모티프 발견 알고리즘\n\n10.1 소개: 문제 정의와 관련성\n10.2 브루트 포스 알고리즘: 완전 탐색\n10.3 분기 및 경계 알고리즘\n10.4 휴리스틱 알고리즘\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n11장. 확률적 모티프와 알고리즘\n\n11.1 확률 모티프 표현 및 검색\n11.2 확률 알고리즘: 기댓값 최대화\n11.3 모티프 발견을 위한 깁스 샘플링\n11.4 바이오파이썬의 확률 모티프\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n12장. 은닉 마르코프 모델\n\n12.1 소개: 은닉 마르코프 모델이란 무엇인가?\n12.2 파이썬으로 알고리즘 구현\n12.3 데이터베이스 검색을 위한 은닉 마르코프 모델\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n13장. 그래프: 개념과 알고리즘\n\n13.1 그래프: 정의와 표현\n13.2 파이썬 클래스 그래프\n13.3 인접 노드와 차수\n13.4 경로, 탐색, 거리\n13.5 사이클\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n14장. 그래프와 생물학적 네트워크\n\n14.1 소개\n14.2 네트워크를 그래프로 표현\n14.3 네트워크 위상 분석\n14.4 대사작용 가능성 평가\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n15장. 게놈으로 리드 어셈블리: 그래프 기반 알고리즘\n\n15.1 게놈 어셈블리 소개 및 관련한 도전들\n15.2 오버랩 그래프와 해밀턴 사이클\n15.3 드브루인 그래프와 오일러 경로\n15.4 실제 게놈 어셈블리\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n16장. 참조 유전자 서열에 리드 어셈블리\n\n16.1 소개: 서열 일치 문제의 정의와 응용법\n16.2 패턴 전처리: 트라이\n16.3 서열의 전처리: 접미사 트리\n16.4 버로우즈 휠러 변환\n참고 문헌과 추가 자료\n연습 문제와 프로그래밍 프로젝트\n\n17장. 더 읽을거리\n\n17.1 추천하는 생명정보학 서적\n17.2 논문 및 학회\n17.3 정규 교육 과정\n17.4 온라인 교육 자료\n\n\n\n\n\n생명과학을 위한 딥러닝\n생물학, 유전체학, 신약 개발에 적용하는 실무 딥러닝\n\n\n분자 데이터에 머신러닝을 적용하는 방법\n딥러닝으로 유전학/유전체학 분석하기\n딥러닝으로 생물물리학 시스템 이해\nDeepChem 라이브러리 소개\n딥러닝을 사용한 현미경 이미지 분석\n딥러닝을 사용한 의료 이미지 분석\nVAE와 GAN 모델\n머신러닝 모델의 작동 원리 해석\n\n\n\n목차\n\n1장. 왜 생명과학인가?\n\n딥러닝은 왜 필요한가?\n현대 생명과학은 빅데이터를 다룬다\n무엇을 배우는가?\n\n2장. 딥러닝 소개\n\n선형 모델\n다층 퍼셉트론\n모델 학습하기\n검증하기\n정규화\n하이퍼파라미터 최적화\n다른 유형의 모델들\n\n합성곱 신경망\n순환 신경망\n\n\n3장. DeepChem을 이용한 머신러닝\n\nDeepChem의 기본 데이터셋\n독성 분자 예측 모델 만들기\nMNIST 데이터셋으로 필기 인식 모델 만들기\n\nMNIST 필기 인식 데이터셋\n합성곱 신경망으로 필기 인식하기\n\n소프트맥스와 소프트맥스 교차 엔트로피\n\n4장. 분자 수준 데이터 다루기\n\n분자란 무엇인가?\n\n분자 간 결합\n분자 그래프\n분자 구조\n분자 카이랄성\n\n분자 데이터 피처화\n\nSMILES 문자열과 RDKit\n확장 연결 지문\n분자 표현자\n\n그래프 합성곱\n용해도 예측 모델\nMoleculeNet\nSMARTS 문자열\n\n5장. 생물물리학과 머신러닝\n\n단백질의 구조\n\n단백질 서열\n\n단백질 3차원 구조를 예측할 수 있을까?\n\n단백질-리간드 결합\n\n생물물리학적 피처화\n\n그리드 피처화\n원자 피처화\n\n생물물리학 데이터 사례 연구\n\nPDBBind 데이터셋\nPDBBind 데이터셋 피처화\n\n\n6장. 유전학과 딥러닝\n\nDNA, RNA, 단백질\n실제 세포 내에서 일어나는 일\n전사인자의 결합\n\n전사인자의 결합을 예측하는 합성곱 모델\n\n염색질 접근성\nRNA 간섭\n\n7장. 현미경을 위한 딥러닝\n\n현미경에 대한 간략한 소개\n\n현대의 광학현미경\n\n회절 한계\n\n전자현미경과 원자현미경\n초고해상도 현미경\n딥러닝과 회절 한계\n\n현미경을 위한 시료 준비\n\n시료 염색하기\n시료 고정\n\n시료 절편 가공\n\n형광현미경\n시료 준비 과정의 영향\n\n딥러닝 활용법\n\n세포수 측정\n\n세포주란 무엇인가?\n\n세포 구별하기\n머신러닝과 실험\n\n\n8장. 의료 체계를 위한 딥러닝\n\n컴퓨터 지원 질병 진단\n베이즈 네트워크를 이용한 불확실성 예측\n전자 건강 기록\nICD-10 코드\n비지도 학습이란 무엇인가?\n\n거대 전자 건강 기록 데이터베이스의 위험성\n\n방사선학을 위한 딥러닝\n\nX선 촬영과 CT 촬영\n조직학\nMRI 촬영\n\n치료법으로서의 머신러닝\n당뇨망막병증\n\n9장. 생성 모델\n\nVAE\nGAN\n생명과학에 생성 모델 응용하기\n\n신약 후보 물질 찾기\n단백질 엔지니어링\n과학적 발견을 위한 도구\n\n생성 모델의 미래\n생성 모델 사용하기\n\n생성 모델 결과 분석\n\n\n10장. 딥러닝 모델의 해석\n\n예측값 설명하기\n입력값 최적화하기\n불확실성 예측하기\n해석 가능성, 설명 가능성, 실제 결과\n\n11장. 가상 선별검사\n\n예측 모델을 위한 데이터셋 준비\n머신러닝 모델 학습하기\n예측을 위한 데이터셋 준비하기\n예측 모델 적용하기\n\n12장. 딥러닝의 미래와 전망\n\n질병 진단\n맞춤 의학\n신약 개발\n생물학 연구\n\n\n\n\n구입처\n\n알라딘\nYES24\n교보문고\n인터파크\n반디앤루니스\n\n\n\n\n파이썬을 활용한 생명정보학 2/e\n\n\n지은이: 티아구 안타오\n옮긴이: 김태윤\n출판사: 에이콘 출판\n\n원제 : Bioinformatics with Python Cookbook - Second Edition\n생명정보학 데이터를 파이썬 프로그래밍 기법과 프레임워크를 사용해 처리한다. 차세대 염기서열 분석, 유전체학, 메타지노믹스(metagenomics), 집단 유전학, 계통 발생학, 프로테오믹스(proteomics)의 내용을 다룬다. 다양한 파이썬 도구와 라이브러리로 데이터를 변환, 분석, 시각화하는 최신 프로그래밍 기법을 배운다. 차세대 염기서열 분석 데이터의 필터링(filtering) 기술과 병렬처리 프레임워크(framework)인 대스크(Dask)와 스파크(Spark)도 소개한다.\n\n\n목차\n\n1장. 파이썬과 주변 생태계\n\n소개\n아나콘다를 사용한 필요 소프트웨어 설치\n도커를 사용한 필요 소프트웨어 설치\nrpy2를 통해 R과 인터페이스 만들기\n주피터 노트북에서 R 매직 명령어 사용하기\n\n2장. 차세대 염기서열 분석\n\n소개\nNCBI와 진뱅크 데이터베이스 둘러보기\n염기서열 분석의 기초\n배우기\nFASTQ 파일 다루기\n정렬 데이터 다루기\nVCF 파일 데이터 분석하기\n게놈 접근성과 SNP 데이터 필터하기\nHTSeq로 NGS 데이터 처리하기\n\n3장. 게놈 데이터 다루기\n\n소개\n좋은 품질의 참조 게놈 다루기\n낮은 품질의 참조 게놈 다루기\n게놈 주석 살펴보기\n게놈 주석으로 원하는 유전자 추출하기\nEnsembl REST API로 오소로그검색\nEnsembl REST API로 유전자 온톨로지 정보 검색\n\n4장. 집단유전학\n\n소개\nPLINK 형식 데이터셋 관리하기\nGenepop 파일 형식 소개\nBio.PopGen으로 데이터셋 탐색하기\nF - 통계 계산하기\n주성분 분석하기\nADMIXTURE 프로그램으로 집단 구조 조사하기\n\n5장. 집단유전학 시뮬레이션\n\n소개\n순방향 시뮬레이터 소개\n선택 시뮬레이션\n섬 모델과 디딤돌 모델을 사용한 시뮬레이션\n복잡한 집단 통계 모델 만들기\n\n6장. 계통 발생학\n\n소개\n계통 발생학 분석을 위한 데이터셋 준비\n유전자와 게놈 데이터 정렬\n서열 데이터 비교하기\n계통수 그리기\n재귀적으로 계통수 다루기\n계통수 시각화하기\n\n7장. 단백질 데이터 뱅크 사용하기\n\n소개\n데이터베이스에서 단백질 정보 찾기\nBio.PDB 소개\nPDB 파일에서 더 많은 정보 추출하기\nPDB 파일에서 분자간 거리 계산\n기하학적 계산하기\nPyMOL로 애니메이션 만들기\nBiopython을 사용해 mmCIF 파일 파싱하기\n\n8장. 생명정보학 파이프라인\n\n소개\n갤럭시 서버 소개\nAPI를 사용해 갤럭시 사용하기\n갤럭시 도구 개발\n일반적인 파이프라인 사용법\nAirflow를 사용해 유전변이 분석 파이프라인 만들기\n\n9장. 파이썬으로 유전체 빅데이터 다루기\n\n소개\nHDF5 데이터 형식\n대스크 라이브러리로 병렬분산처리\n파케이 데이터 형식\n스파크 라이브러리로 병렬분산처리\n사이썬과 눔바로 코드 최적화\n\n10장. 생명정보학의 다른 주제들\n\n소개\nQIIME2로 메타지노믹스 분석하기\n생식세포계열로 공통 염색체 찾기\nREST API로 GBIF 데이터베이스 사용하기\nGBIF의 지리 참조 데이터 다루기\n사이토스케이프로 단백질 네트워크 시각화\n\n11장. 고급 차세대 염기서열 분석\n\n소개\n분석을 위한 데이터셋 준비하기\n멘델리언 오류로 데이터 품질 관리\n의사 결정 나무를 사용한 데이터 탐색\n표준 통계로 데이터 탐색\n주석 데이터로 생물학적 특성 찾기\n\n\n\n\n구입처\n\n알라딘\nYES24\n교보문고\n인터파크\n반디앤루니스"
  }
]